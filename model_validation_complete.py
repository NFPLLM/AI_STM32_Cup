# model_validation_complete.py
import os
import cv2
import re  # æ–°å¢ï¼šç”¨äºè§£ææ¨¡å‹ä¿¡æ¯å­—ç¬¦ä¸²
import json  # æ–°å¢ï¼šç”¨äºç”ŸæˆJSONæŠ¥å‘Š
import numpy as np
import matplotlib.pyplot as plt
from ultralytics import YOLO
import onnxruntime as ort
from sklearn.metrics import precision_recall_curve, average_precision_score


class ModelValidator:
    def __init__(self, model_path):
        self.model_path = model_path
        self.model = None
        self.ort_session = None

    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        if self.model_path.endswith('.pt'):
            self.model = YOLO(self.model_path)
            print(f"PyTorchæ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
            return True
        elif self.model_path.endswith('.onnx'):
            self.ort_session = ort.InferenceSession(self.model_path)
            print(f"ONNXæ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
            return True
        else:
            print(f"ä¸æ”¯æŒçš„æ¨¡å‹æ ¼å¼: {self.model_path}")
            return False

    def validate_accuracy(self, data_config):
        """éªŒè¯æ¨¡å‹ç²¾åº¦ï¼ˆä¿®å¤ï¼šå¤„ç†å¬å›ç‡æ•°ç»„é—®é¢˜ï¼‰"""
        if self.model is None:
            print("PyTorchæ¨¡å‹æœªåŠ è½½")
            return None

        print("å¼€å§‹ç²¾åº¦éªŒè¯...")
        metrics = self.model.val(data=data_config, split='val')

        # å¤„ç†ç²¾ç¡®ç‡ï¼šè‹¥ä¸ºæ•°ç»„å–ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆæ‰€æœ‰ç±»å¹³å‡ï¼‰
        precision = metrics.box.p[0] if isinstance(metrics.box.p, np.ndarray) else metrics.box.p
        # å¤„ç†å¬å›ç‡ï¼šåŒä¸Šï¼ˆä¿®å¤æ ¸å¿ƒç‚¹ï¼‰
        recall = metrics.box.r[0] if isinstance(metrics.box.r, np.ndarray) else metrics.box.r

        print("\n=== ç²¾åº¦éªŒè¯ç»“æœ ===")
        print(f"mAP50: {metrics.box.map50:.4f}")
        print(f"mAP50-95: {metrics.box.map:.4f}")
        print(f"ç²¾ç¡®ç‡: {precision:.4f}")
        print(f"å¬å›ç‡: {recall:.4f}")

        return {
            'mAP50': metrics.box.map50,
            'mAP50-95': metrics.box.map,
            'precision': precision,
            'recall': recall
        }

    def test_inference_speed(self, num_iterations=50):
        """æµ‹è¯•æ¨ç†é€Ÿåº¦ï¼ˆä¼˜åŒ–ï¼šå¤„ç†åŠ¨æ€è¾“å…¥å½¢çŠ¶ï¼‰"""
        if self.ort_session is None:
            print("ONNXæ¨¡å‹æœªåŠ è½½")
            return None

        input_name = self.ort_session.get_inputs()[0].name
        input_shape = self.ort_session.get_inputs()[0].shape

        # ä¼˜åŒ–ï¼šå¤„ç†åŠ¨æ€ç»´åº¦ï¼ˆå¦‚[-1,3,-1,-1]ï¼‰ï¼Œæ›¿æ¢ä¸ºå›ºå®šå°ºå¯¸(1,3,640,640)
        fixed_input_shape = []
        for dim in input_shape:
            if dim == '?' or dim < 1:  # ONNXåŠ¨æ€ç»´åº¦å¯èƒ½ç”¨?æˆ–è´Ÿæ•°è¡¨ç¤º
                fixed_input_shape.append(640 if len(fixed_input_shape) in [2, 3] else 1)
            else:
                fixed_input_shape.append(dim)
        fixed_input_shape = tuple(fixed_input_shape)

        # åˆ›å»ºæµ‹è¯•è¾“å…¥ï¼ˆä½¿ç”¨å›ºå®šå½¢çŠ¶ï¼‰
        test_input = np.random.randn(*fixed_input_shape).astype(np.float32)

        # é¢„çƒ­
        for _ in range(10):
            self.ort_session.run(None, {input_name: test_input})

        # æ­£å¼æµ‹è¯•
        import time
        times = []
        for i in range(num_iterations):
            start_time = time.perf_counter()
            self.ort_session.run(None, {input_name: test_input})
            end_time = time.perf_counter()
            times.append((end_time - start_time) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’

        # åˆ†æç»“æœ
        avg_time = np.mean(times)
        std_time = np.std(times)
        min_time = np.min(times)
        max_time = np.max(times)

        print("\n=== æ¨ç†é€Ÿåº¦æµ‹è¯• ===")
        print(f"è¾“å…¥å½¢çŠ¶: {fixed_input_shape}")
        print(f"å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.2f} Â± {std_time:.2f} ms")
        print(f"æœ€å¿«æ¨ç†æ—¶é—´: {min_time:.2f} ms")
        print(f"æœ€æ…¢æ¨ç†æ—¶é—´: {max_time:.2f} ms")
        print(f"ç†è®ºFPS: {1000 / avg_time:.2f}")

        # STM32æ€§èƒ½é¢„ä¼°
        stm32_factor = 15  # STM32æ¯”PCæ…¢çš„å€æ•°ï¼ˆå¯æ ¹æ®å®é™…ç¡¬ä»¶è°ƒæ•´ï¼‰
        stm32_avg_time = avg_time * stm32_factor
        stm32_fps = 1000 / stm32_avg_time

        print(f"\nSTM32æ€§èƒ½é¢„ä¼°:")
        print(f"é¢„ä¼°æ¨ç†æ—¶é—´: {stm32_avg_time:.1f} ms")
        print(f"é¢„ä¼°FPS: {stm32_fps:.1f}")

        return {
            'pc_avg_time_ms': avg_time,
            'pc_fps': 1000 / avg_time,
            'stm32_avg_time_ms': stm32_avg_time,
            'stm32_fps': stm32_fps
        }

    def visualize_detections(self, image_paths, output_dir='validation_results'):
        """å¯è§†åŒ–æ£€æµ‹ç»“æœ"""
        if self.model is None:
            print("PyTorchæ¨¡å‹æœªåŠ è½½")
            return

        os.makedirs(output_dir, exist_ok=True)
        print(f"å¯è§†åŒ–æ£€æµ‹ç»“æœï¼Œä¿å­˜è‡³: {output_dir}")

        for i, image_path in enumerate(image_paths):
            if not os.path.exists(image_path):
                print(f"å›¾åƒä¸å­˜åœ¨: {image_path}")
                continue

            # è¿›è¡Œæ¨ç†ï¼ˆè®¾ç½®conf=0.3æé«˜æ£€æµ‹å¬å›ç‡ï¼‰
            results = self.model(image_path, conf=0.3)

            # ç»˜åˆ¶å¹¶ä¿å­˜ç»“æœ
            for r in results:
                im_array = r.plot()  # YOLOå†…ç½®å¯è§†åŒ–
                output_path = os.path.join(output_dir, f'detection_{i + 1}.png')
                cv2.imwrite(output_path, im_array)
                print(f"ä¿å­˜æ£€æµ‹ç»“æœ: {output_path}")

    def analyze_model_complexity(self):
        """åˆ†ææ¨¡å‹å¤æ‚åº¦ï¼ˆä¿®å¤ï¼šå¤„ç†å…ƒç»„æ ¼å¼çš„model.info()è¿”å›å€¼ï¼‰"""
        if self.model is None:
            print("PyTorchæ¨¡å‹æœªåŠ è½½")
            return None

        # è·å–æ¨¡å‹ä¿¡æ¯ï¼ˆå…ƒç»„æ ¼å¼ï¼š(å±‚æ•°, å‚æ•°é‡, æ¢¯åº¦æ•°, GFLOPs)ï¼‰
        model_info_tuple = self.model.info()
        print("\næ¨¡å‹åŸå§‹ä¿¡æ¯ï¼ˆå…ƒç»„ï¼‰:")
        print(model_info_tuple)

        # ä»å…ƒç»„ä¸­æå–ä¿¡æ¯ï¼ˆæŒ‰å›ºå®šä½ç½®è§£æï¼‰
        layers = model_info_tuple[0] if len(model_info_tuple) > 0 else None
        params = model_info_tuple[1] if len(model_info_tuple) > 1 else None
        gradients = model_info_tuple[2] if len(model_info_tuple) > 2 else None
        gflops = model_info_tuple[3] if len(model_info_tuple) > 3 else None

        # è®¡ç®—æ¨¡å‹æ–‡ä»¶å¤§å°
        model_size_mb = os.path.getsize(self.model_path) / 1024 / 1024 if os.path.exists(self.model_path) else None

        # æ‰“å°åˆ†æç»“æœ
        print("\n=== æ¨¡å‹å¤æ‚åº¦åˆ†æ ===")
        print(f"å±‚æ•°: {layers}" if layers is not None else "å±‚æ•°: æ— æ³•è·å–")
        print(f"å‚æ•°é‡: {params:,}" if params is not None else "å‚æ•°é‡: æ— æ³•è·å–")
        print(f"æ¢¯åº¦æ•°é‡: {gradients:,}" if gradients is not None else "æ¢¯åº¦æ•°é‡: æ— æ³•è·å–")
        print(f"è®¡ç®—é‡: {gflops:.2f} GFLOPs" if gflops is not None else "è®¡ç®—é‡: æ— æ³•è·å–")
        print(f"æ¨¡å‹å¤§å°: {model_size_mb:.2f} MB" if model_size_mb else "æ¨¡å‹å¤§å°: æ— æ³•è·å–")

        # è¿”å›ç»“æ„åŒ–ä¿¡æ¯
        return {
            'layers': layers,
            'parameters': params,
            'gradients': gradients,
            'gflops': gflops,
            'model_size_mb': model_size_mb
        }

    def generate_validation_report(self, accuracy_results, speed_results, output_file='validation_report.json'):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Šï¼ˆä¿®å¤ï¼šå¤„ç†speed_resultsä¸ºNoneçš„æƒ…å†µï¼‰"""
        # åˆå§‹åŒ–æŠ¥å‘ŠåŸºç¡€ä¿¡æ¯
        report = {
            'validation_date': str(np.datetime64('now')),
            'model_path': self.model_path,
            'accuracy_metrics': accuracy_results or {},  # è‹¥ä¸ºNoneåˆ™è®¾ä¸ºç©ºå­—å…¸
            'performance_metrics': speed_results or {},  # è‹¥ä¸ºNoneåˆ™è®¾ä¸ºç©ºå­—å…¸
            'hardware_compatibility': {
                'recommended_ram': '512KB',
                'recommended_flash': '8MB',
                'suitable_for_stm32': False,
                'performance_level': 'Unknown'
            },
            'recommendations': []
        }

        # ä¿®å¤ï¼šä»…å½“speed_resultså­˜åœ¨æ—¶ï¼Œåˆ¤æ–­STM32å…¼å®¹æ€§
        if speed_results and 'stm32_fps' in speed_results:
            stm32_fps = speed_results['stm32_fps']
            report['hardware_compatibility']['suitable_for_stm32'] = stm32_fps >= 2.0
            report['hardware_compatibility']['performance_level'] = 'Good' if stm32_fps >= 2.0 else 'Limited'

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        if accuracy_results and accuracy_results.get('mAP50', 0) < 0.4:
            report['recommendations'].append("è€ƒè™‘å¢åŠ è®­ç»ƒæ•°æ®æˆ–è°ƒæ•´è®­ç»ƒå‚æ•°ï¼ˆå¦‚å¢å¤§epochã€è°ƒæ•´å­¦ä¹ ç‡ï¼‰")
        if speed_results and speed_results.get('stm32_fps', 0) < 2.0:
            report['recommendations'].append("å»ºè®®ä½¿ç”¨æ›´å°çš„è¾“å…¥å°ºå¯¸ï¼ˆå¦‚416x416ï¼‰æˆ–æ¨¡å‹é‡åŒ–ï¼ˆå¦‚INT8ï¼‰")
        if not report['recommendations']:
            report['recommendations'].append("æ¨¡å‹æ€§èƒ½æ»¡è¶³åŸºç¡€éœ€æ±‚ï¼Œå¯æ ¹æ®å®é™…åœºæ™¯è¿›ä¸€æ­¥ä¼˜åŒ–")

        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"\néªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        return report

    def run_complete_validation(self, data_config, test_images=None):
        """è¿è¡Œå®Œæ•´çš„éªŒè¯æµç¨‹"""
        print("=" * 50)
        print("å¼€å§‹å®Œæ•´çš„æ¨¡å‹éªŒè¯æµç¨‹...")
        print("=" * 50)

        # 1. åŠ è½½æ¨¡å‹
        if not self.load_model():
            print("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œç»ˆæ­¢éªŒè¯æµç¨‹")
            return False

        # 2. éªŒè¯ç²¾åº¦ï¼ˆä»…PyTorchæ¨¡å‹æ”¯æŒï¼‰
        print("\n1. éªŒè¯æ¨¡å‹ç²¾åº¦...")
        accuracy_results = self.validate_accuracy(data_config)

        # 3. åˆ†ææ¨¡å‹å¤æ‚åº¦
        print("\n2. åˆ†ææ¨¡å‹å¤æ‚åº¦...")
        complexity_results = self.analyze_model_complexity()

        # 4. æµ‹è¯•æ¨ç†é€Ÿåº¦ï¼ˆä»…ONNXæ¨¡å‹æ”¯æŒï¼‰
        print("\n3. æµ‹è¯•æ¨ç†é€Ÿåº¦...")
        speed_results = self.test_inference_speed()

        # 5. å¯è§†åŒ–æ£€æµ‹ç»“æœï¼ˆå¯é€‰ï¼‰
        if test_images:
            print("\n4. å¯è§†åŒ–æ£€æµ‹ç»“æœ...")
            self.visualize_detections(test_images)
        else:
            print("\n4. å¯è§†åŒ–æ£€æµ‹ç»“æœ... æœªæä¾›æµ‹è¯•å›¾ç‰‡è·¯å¾„ï¼Œè·³è¿‡æ­¤æ­¥éª¤")

        # 6. ç”ŸæˆéªŒè¯æŠ¥å‘Š
        print("\n5. ç”ŸæˆéªŒè¯æŠ¥å‘Š...")
        report = self.generate_validation_report(accuracy_results, speed_results)

        print("\n" + "=" * 50)
        print("âœ… å®Œæ•´éªŒè¯æµç¨‹å®Œæˆ!")
        print("=" * 50)
        return report


def main():
    """ä¸»å‡½æ•°ï¼ˆå¯æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´ï¼‰"""
    # 1. é…ç½®è·¯å¾„ï¼ˆè¯·ç¡®ä¿è¿™ä¸¤ä¸ªè·¯å¾„æ­£ç¡®ï¼‰
    model_path = 'cup_detection/yolov8n_cup_improved/weights/best.pt'  # .ptæˆ–.onnxæ¨¡å‹è·¯å¾„
    data_config = 'coco_cup_dataset/dataset.yaml'  # æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
    # å¯é€‰ï¼šæµ‹è¯•å›¾ç‰‡è·¯å¾„ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰ï¼Œè‹¥ä¸éœ€è¦å¯è®¾ä¸ºNone
    test_images = [
        # "test_images/cup1.jpg",
        # "test_images/cup2.jpg"
    ]

    # 2. åˆå§‹åŒ–éªŒè¯å™¨å¹¶è¿è¡Œ
    validator = ModelValidator(model_path)
    report = validator.run_complete_validation(data_config, test_images)

    # 3. æ‰“å°æŠ¥å‘Šæ‘˜è¦
    if report and report.get('accuracy_metrics'):
        print("\nğŸ“Š éªŒè¯æŠ¥å‘Šæ‘˜è¦:")
        acc = report['accuracy_metrics']
        print(f"ç²¾åº¦ - mAP50: {acc.get('mAP50', 0):.4f}, ç²¾ç¡®ç‡: {acc.get('precision', 0):.4f}, å¬å›ç‡: {acc.get('recall', 0):.4f}")
        if report.get('performance_metrics'):
            perf = report['performance_metrics']
            print(f"æ€§èƒ½ - PC FPS: {perf.get('pc_fps', 0):.1f}, STM32é¢„ä¼°FPS: {perf.get('stm32_fps', 0):.1f}")
        print(f"ç¡¬ä»¶é€‚é… - é€‚åˆSTM32: {report['hardware_compatibility']['suitable_for_stm32']}")


if __name__ == "__main__":
    main()